{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Final_ChatBot_DNN_With_Tensorboard.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeQKLq4OO_TW",
        "outputId": "359f58f9-8a6e-48d6-e5ab-ec1f585c905f"
      },
      "source": [
        "!pip install tflearn"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tflearn in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tflearn) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tflearn) (1.19.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from tflearn) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we used tensorboard to visualize the accuracy and loss graphs"
      ],
      "metadata": {
        "id": "a_PQhkCzX4JW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rm -rf ./logs/"
      ],
      "metadata": {
        "id": "66YGE7J9TulE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard "
      ],
      "metadata": {
        "id": "0WDtS3rYTwZY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXU-E_EcHimM",
        "outputId": "70d755f5-ea32-400c-c910-d0c93127d31a"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tflearn\n",
        "import random\n",
        "import json\n",
        "import pickle\n",
        "import datetime, os\n",
        "\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='./Graph', histogram_freq=1)\n",
        "\n",
        "import tensorflow as tflow"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnzfH4CFRo-D"
      },
      "source": [
        "# **DATA PRE-PROCESSING**\n",
        "pattern = questions\n",
        "\n",
        "tag = type of question\n",
        "\n",
        "response = answer of pattern"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1qeaAH7PdAG"
      },
      "source": [
        "stemmer = LancasterStemmer()\n",
        "\n",
        "# accessing the json file that has the questions and answers\n",
        "with open(\"dataset.json\") as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "#print(data)\n",
        "#print(data[\"intents\"])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SewgWRdGPvvv"
      },
      "source": [
        "try:\n",
        "    x    # uncomment the 'x' after changing the JSON file so that it reprocesses the new changes\n",
        "    with open(\"data.pickle\", \"rb\") as f:\n",
        "        words, labels, training, output = pickle.load(f)  # loads variables into pickle file, and then reuses them\n",
        "\n",
        "except:\n",
        "    words = []  # tokenized words of the pattern\n",
        "    labels = [] # tag labels we used\n",
        "    docs_x = [] # for each word in pattern/question in docs_x we have\n",
        "    docs_y = [] # the intent tag it has in docs_y\n",
        "\n",
        "    # tokinizing the words of the statements\n",
        "    for intent in data[\"intents\"]:\n",
        "        for pattern in intent[\"patterns\"]:\n",
        "            wrds = nltk.word_tokenize(pattern)\n",
        "            words.extend(wrds)\n",
        "            docs_x.append(wrds)        \n",
        "            docs_y.append(intent[\"tag\"])  \n",
        "\n",
        "        if intent[\"tag\"] not in labels:\n",
        "            labels.append(intent[\"tag\"])\n",
        "\n",
        "    # stemming the questions into base words\n",
        "    words = [stemmer.stem(w.lower()) for w in words if w != \"?\"]  #takes the pattern words and sets them to small caps for equal consideration\n",
        "    words = sorted(list(set(words)))                              # set removes duplicates, then return into sorted words\n",
        "\n",
        "    labels = sorted(labels)\n",
        "\n",
        "    # creating bag of words: one hot encoding\n",
        "    training = []\n",
        "    output = []\n",
        "\n",
        "    out_empty = [0 for _ in range(len(labels))]\n",
        "\n",
        "    for question, doc in enumerate(docs_x):\n",
        "        bag = []\n",
        "        wrds = [stemmer.stem(w) for w in doc]\n",
        "\n",
        "        for w in words:\n",
        "            if w in wrds:\n",
        "                bag.append(1)   # holds 1 if the word exists in pattern\n",
        "            else:\n",
        "                bag.append(0)   # holds 0 if the word is not in pattern\n",
        "        \n",
        "        output_row = out_empty[:]\n",
        "        output_row[labels.index(docs_y[question])] = 1     # we look through our used tags and set it to 1 in ouput_row\n",
        "        training.append(bag)                               # training data\n",
        "        output.append(output_row)                          # output data\n",
        "\n",
        "    # turning them into numpy arrays for model use\n",
        "    training = np.array(training)\n",
        "    output = np.array(output)\n",
        "\n",
        "    with open(\"data.pickle\", \"wb\") as f:\n",
        "        pickle.dump((words, labels, training, output), f)  # saves variables into pickle file, and then reuses them\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sJZMIxiX03z"
      },
      "source": [
        "# MODEL TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AmvgfWuXzwY",
        "outputId": "25fe9d59-c9a5-496c-d4c0-252d6db6843c"
      },
      "source": [
        "# tensorflow and tflearn model\n",
        "net = tflearn.input_data(shape = [None, len(training[0])])\n",
        "\n",
        "# add more neurons and/or layers for more data and/or more tags\n",
        "net = tflearn.fully_connected(net, 600, activation = 'relu')   # connect first hidden layer of network with 8 nodes\n",
        "net = tflearn.fully_connected(net, 1222, activation = 'relu')   # second hidden layer\n",
        "net = tflearn.fully_connected(net, 1200, activation = 'relu')   # third hidden layer\n",
        "net = tflearn.fully_connected(net, 1000, activation = 'relu')   # fifth hidden layer\n",
        "net = tflearn.fully_connected(net, 500, activation = 'relu')   # fifth hidden layer\n",
        "net = tflearn.fully_connected(net, 200, activation = 'relu')   # fifth hidden layer\n",
        "\n",
        "# output layer: softmax allows us to get probability for each output tag according to the input\n",
        "net = tflearn.fully_connected(net, len(output[0]), activation = \"softmax\") \n",
        "\n",
        "net = tflearn.regression(net, optimizer = 'adam', loss = 'categorical_crossentropy')\n",
        "\n",
        "model = tflearn.DNN(net, checkpoint_path='/tmp/tflearn_logs/', tensorboard_verbose=0)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tflearn/initializations.py:165: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQLwPQ_Pa8RU",
        "outputId": "53e9b664-37f4-4e5d-993a-a0bdb0e6e84c"
      },
      "source": [
        "model.fit(training, output, n_epoch = 310, batch_size = 150,show_metric = True,run_id='Chatbot')\n",
        "model.save(\"model.tflearn\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Step: 929  | total loss: \u001b[1m\u001b[32m1.47647\u001b[0m\u001b[0m | time: 0.150s\n",
            "| Adam | epoch: 310 | loss: 1.47647 - acc: 0.9062 -- iter: 300/303\n",
            "Training Step: 930  | total loss: \u001b[1m\u001b[32m1.33751\u001b[0m\u001b[0m | time: 0.260s\n",
            "| Adam | epoch: 310 | loss: 1.33751 - acc: 0.9109 -- iter: 303/303\n",
            "--\n",
            "INFO:tensorflow:/tmp/tflearn_logs/-930 is not in all_model_checkpoint_paths. Manually adding it.\n",
            "INFO:tensorflow:/content/model.tflearn is not in all_model_checkpoint_paths. Manually adding it.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorboard dev upload \\\n",
        "  --logdir '/tmp/tflearn_logs/Chatbot' \\\n",
        "  --name \"Chatbot\" \\\n",
        "  --one_shot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGkIHoBoUMe5",
        "outputId": "bc8ddbe6-381e-45f6-b40f-6ac5b9ec4f71"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-12-11 21:31:40.081352: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\n",
            "New experiment created. View your TensorBoard at: https://tensorboard.dev/experiment/0IYJzeoKSJWwfaNKboBYOw/\n",
            "\n",
            "\u001b[1m[2021-12-11T21:31:40]\u001b[0m Started scanning logdir.\n",
            "E1211 21:31:41.643534 139670005086080 uploader.py:1122] Attempted to re-upload existing blob.  Skipping.\n",
            "E1211 21:31:42.624364 139670005086080 uploader.py:1122] Attempted to re-upload existing blob.  Skipping.\n",
            "\u001b[1m[2021-12-11T21:31:43]\u001b[0m Total uploaded: 3948 scalars, 0 tensors, 1 binary objects (151.4 kB)\n",
            "\u001b[90mTotal skipped: 2 binary objects (302.8 kB)\n",
            "\u001b[0m\u001b[1m[2021-12-11T21:31:43]\u001b[0m Done scanning logdir.\n",
            "\n",
            "\n",
            "Done. View your TensorBoard at https://tensorboard.dev/experiment/0IYJzeoKSJWwfaNKboBYOw/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vpxorh91noeo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e48438c-91ad-4b28-fb5e-1ea53181596d"
      },
      "source": [
        "# function that bags the user input words, and changes them into numpy arrays for use for model\n",
        "def bag_of_words(s, words):\n",
        "    bag = [0 for _ in range(len(words))]\n",
        "\n",
        "    s_words = nltk.word_tokenize(s)\n",
        "    s_words = [stemmer.stem(word.lower()) for word in s_words]\n",
        "\n",
        "    for se in s_words:\n",
        "        for i, w in enumerate(words):\n",
        "            if w == se:\n",
        "                bag[i] = 1\n",
        "\n",
        "    return np.array(bag)\n",
        "\n",
        "# function to start chatting with the bot/model\n",
        "def chat():\n",
        "    print(\"Start talking with AUBot (type quit to stop)!\")\n",
        "\n",
        "    while True:\n",
        "        inp = input(\"\\nYou: \")\n",
        "        if inp.lower() == \"quit\":\n",
        "            break\n",
        "\n",
        "        print(\"\\nAUBot: \")\n",
        "\n",
        "        results = model.predict([bag_of_words(inp, words)])  # classifies the input into a probability array of what tag it should be\n",
        "        #print(results)\n",
        "        results_index = np.argmax(results)  # index of highest probabile tag\n",
        "        tag = labels[results_index]\n",
        "        #print(tag)\n",
        "\n",
        "        for tg in data[\"intents\"]:\n",
        "            if tg['tag'] == tag:\n",
        "                responses = tg['responses']\n",
        "\n",
        "        print(random.choice(responses))\n",
        "\n",
        "chat()\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start talking with AUBot (type quit to stop)!\n",
            "\n",
            "You: what's up\n",
            "\n",
            "AUBot: \n",
            "Hello! how are doing today?\n",
            "\n",
            "You: how are you doing\n",
            "\n",
            "AUBot: \n",
            "I am doing just fine. Please ask me some question.\n",
            "\n",
            "You: what's your name\n",
            "\n",
            "AUBot: \n",
            "You can call me AUBot.\n",
            "\n",
            "You: what can I ask you\n",
            "\n",
            "AUBot: \n",
            "i can answer AUB related questions relavant to transcripts, financial aid, capacities, petitions, registration, transfer, and work study.\n",
            "\n",
            "You: what does a negative value mean on the web statement of fees\n",
            "\n",
            "AUBot: \n",
            "It is for financial aid, what you have removed. The statement will update later.\n",
            "\n",
            "You: does financial aid cover the summer semester\n",
            "\n",
            "AUBot: \n",
            "If you ask nicely maybe \n",
            "\n",
            "You: when does the registrar open\n",
            "\n",
            "AUBot: \n",
            "Registrar, Cashier and Comptroller's offices are from 8 a.m. to 4 p.m. M-F outside of holidays.\n",
            "\n",
            "You: how do I submit a petition\n",
            "\n",
            "AUBot: \n",
            "go to the following link: https://epetitions.aub.edu.lb/.\n",
            "\n",
            "You: my web statement of fees is not updated even though I paid\n",
            "\n",
            "AUBot: \n",
            "Check with the Comptroller's at AUB College hall. Usually take a week to update.\n",
            "\n",
            "You: how do i get payment from the work study program\n",
            "\n",
            "AUBot: \n",
            "Currently, they are giving from 13,000 to 16,000 L.L per hour, usually either to remove from tuition, or to get it cash. Some jobs have more money but you get them removed from tuition.\n",
            "\n",
            "You: where can I find the financial aid application\n",
            "\n",
            "AUBot: \n",
            "The online application for AY 2020-21 will be available starting February 10, 2020 and the deadline to submit the hard copy and the required documents is May 29, 2020.\n",
            "\n",
            "You: where can I see my financial aid result\n",
            "\n",
            "AUBot: \n",
            "Go to aubsis, press the last tab in the middle \"Student Awards and Financial Aid\", and then 'view my student aid'. it should be there.\n",
            "\n",
            "You: when does jafet library open\n",
            "\n",
            "AUBot: \n",
            "Jafet Library Computer labs and Reading areas are open Monday - Friday: 07:30 AM - 09:00 PM, Saturday: 08:00 AM - 05:00 PM, Sunday: Noon - 08:00 PM\n",
            "\n",
            "You: when are the opening hours of the gym\n",
            "\n",
            "AUBot: \n",
            "CHSC opening hours are Monday to Friday from 7:00am till 7:00pm and Saturday from 9am till 5pm. Note that the gym is closed on Sundays.\n",
            "\n",
            "You: okay thank you\n",
            "\n",
            "AUBot: \n",
            "dont mention it :)\n",
            "\n",
            "You: have a good day\n",
            "\n",
            "AUBot: \n",
            "Goodbye!\n",
            "\n",
            "You: quit\n"
          ]
        }
      ]
    }
  ]
}